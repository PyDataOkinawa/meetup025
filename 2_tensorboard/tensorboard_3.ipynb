{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可視化のための情報を記録（summary）\n",
    "\n",
    "Tensor ---(Summary operation)---> Protocol buffer ---(Summary writer)---> Disk\n",
    "\n",
    "## Summary operation\n",
    "\n",
    "- tf.summary.scalar\n",
    "- tf.summary.image\n",
    "- tf.summary.audio\n",
    "- tf.summary.histogram\n",
    "- tf.summary.tensor (under development)\n",
    "\n",
    "## Summary writer (tf.summary.FileWriter)\n",
    "\n",
    "- writer = tf.summary.FileWriter(LOGDIR)\n",
    "- writer.add_graph(sess.graph)\n",
    "- writer.add_summary(s, global_step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoardで学習を可視化\n",
    "\n",
    "- [TensorBoard: Visualizing Learning](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n",
    "- [Dandelion Mané on GitHub](https://github.com/dandelionmane)\n",
    "- https://github.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST\n",
    "- C - P - C - P - F - F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOGDIR = '/tmp/mnist_demo/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(LOGDIR):\n",
    "    shutil.rmtree(LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レイヤーを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 畳み込み層\n",
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.zeros([5, 5, channels_in, channels_out]), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([channels_out]), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        pool = tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")        \n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全結合層　\n",
    "def fc_layer(input, channels_in, channels_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.zeros([channels_in, channels_out]), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([channels_out]), name=\"B\")\n",
    "        logits = tf.matmul(input, w)+ b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 入力と出力を保持するプレースホルダを用意し、入力を変形\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "tf.summary.image(\"input\", x_image, 3)\n",
    "\n",
    "# ネットワークを構築\n",
    "conv1 = conv_layer(x_image, 1, 32, name=\"conv1\")\n",
    "conv2 = conv_layer(conv1, 32, 64, name=\"conv2\")\n",
    "flattened = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "\n",
    "fc1_logits = fc_layer(flattened, 7 * 7 * 64, 1024, name=\"fc1\")\n",
    "fc1 = tf.nn.relu(fc1_logits)\n",
    "logits = fc_layer(fc1, 1024, 10, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数と最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数にはクロスエントロピーを使用\n",
    "with tf.name_scope(\"xent\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    tf.summary.scalar(\"xent\", cross_entropy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最適化手法にはAdamを使用\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 正答率を計算\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 変数の初期化\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorBoard用の準備\n",
    "writer = tf.summary.FileWriter(LOGDIR)  # FileWriterとイベントファイルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 計算グラフの可視化\n",
    "writer.add_graph(sess.graph)  # 計算グラフ（Graph）をイベントファイルに書き出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summary opからの情報を集める処理\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.07\n",
      "---- step 0, test accuracy 0.0849609\n",
      "step 5, training accuracy 0.15\n",
      "step 10, training accuracy 0.1\n",
      "step 15, training accuracy 0.08\n",
      "step 20, training accuracy 0.07\n",
      "step 25, training accuracy 0.08\n",
      "step 30, training accuracy 0.09\n",
      "step 35, training accuracy 0.16\n",
      "step 40, training accuracy 0.18\n",
      "step 45, training accuracy 0.11\n",
      "step 50, training accuracy 0.1\n",
      "---- step 50, test accuracy 0.126953\n",
      "step 55, training accuracy 0.12\n",
      "step 60, training accuracy 0.09\n",
      "step 65, training accuracy 0.08\n",
      "step 70, training accuracy 0.08\n",
      "step 75, training accuracy 0.1\n",
      "step 80, training accuracy 0.14\n",
      "step 85, training accuracy 0.07\n",
      "step 90, training accuracy 0.09\n",
      "step 95, training accuracy 0.13\n",
      "step 100, training accuracy 0.05\n",
      "---- step 100, test accuracy 0.126953\n",
      "step 105, training accuracy 0.1\n",
      "step 110, training accuracy 0.13\n",
      "step 115, training accuracy 0.14\n",
      "step 120, training accuracy 0.17\n",
      "step 125, training accuracy 0.13\n",
      "step 130, training accuracy 0.11\n",
      "step 135, training accuracy 0.2\n",
      "step 140, training accuracy 0.1\n",
      "step 145, training accuracy 0.11\n",
      "step 150, training accuracy 0.14\n",
      "---- step 150, test accuracy 0.126953\n",
      "step 155, training accuracy 0.16\n",
      "step 160, training accuracy 0.17\n",
      "step 165, training accuracy 0.09\n",
      "step 170, training accuracy 0.08\n",
      "step 175, training accuracy 0.12\n",
      "step 180, training accuracy 0.15\n",
      "step 185, training accuracy 0.14\n",
      "step 190, training accuracy 0.06\n",
      "step 195, training accuracy 0.13\n",
      "step 200, training accuracy 0.11\n",
      "---- step 200, test accuracy 0.126953\n",
      "step 205, training accuracy 0.1\n",
      "step 210, training accuracy 0.13\n",
      "step 215, training accuracy 0.1\n",
      "step 220, training accuracy 0.09\n",
      "step 225, training accuracy 0.06\n",
      "step 230, training accuracy 0.11\n",
      "step 235, training accuracy 0.11\n",
      "step 240, training accuracy 0.15\n",
      "step 245, training accuracy 0.06\n",
      "step 250, training accuracy 0.06\n",
      "---- step 250, test accuracy 0.126953\n"
     ]
    }
   ],
   "source": [
    "# 250ステップ学習\n",
    "for i in range(251):\n",
    "    \n",
    "    batch = mnist.train.next_batch(100)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        [train_accuracy, s] = sess.run([accuracy, merged_summary], feed_dict={x: batch[0], y: batch[1]})\n",
    "        writer.add_summary(s, global_step=i)\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        \n",
    "    if i % 50 == 0:\n",
    "        [test_accuracy] = sess.run([accuracy], feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "        print(\"---- step %d, test accuracy %g\" % (i, test_accuracy))\n",
    "        \n",
    "    # 学習\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoardの呼び出し\n",
    "\n",
    "tensorboard --logdir /tmp/mnist_demo/3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
